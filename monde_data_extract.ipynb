{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import django\n",
    "import os\n",
    "import json\n",
    "os.environ['DJANGO_SETTINGS_MODULE'] = 'django_settings'\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from boto3.session import Session\n",
    "import boto3\n",
    "import botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data_management.models import *\n",
    "from loader import load_credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY = load_credential(\"AWS_ACCESS_KEY_ID\",\"\")\n",
    "SECRET_ACCESS_KEY = load_credential(\"AWS_SECRET_ACCESS_KEY\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<QuerySet [<CroppedImage: CroppedImage object (178)>, <CroppedImage: CroppedImage object (179)>, <CroppedImage: CroppedImage object (180)>, <CroppedImage: CroppedImage object (181)>, <CroppedImage: CroppedImage object (182)>, <CroppedImage: CroppedImage object (183)>, <CroppedImage: CroppedImage object (184)>, <CroppedImage: CroppedImage object (185)>, <CroppedImage: CroppedImage object (186)>, <CroppedImage: CroppedImage object (187)>, <CroppedImage: CroppedImage object (188)>, <CroppedImage: CroppedImage object (189)>, <CroppedImage: CroppedImage object (190)>, <CroppedImage: CroppedImage object (191)>, <CroppedImage: CroppedImage object (192)>, <CroppedImage: CroppedImage object (193)>, <CroppedImage: CroppedImage object (194)>, <CroppedImage: CroppedImage object (195)>, <CroppedImage: CroppedImage object (196)>, <CroppedImage: CroppedImage object (197)>, '...(remaining elements truncated)...']>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CroppedImage.objects.select_related('origin_source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<QuerySet [<ProductCategories: ProductCategories object (11)>, <ProductCategories: ProductCategories object (12)>, <ProductCategories: ProductCategories object (13)>, <ProductCategories: ProductCategories object (14)>, <ProductCategories: ProductCategories object (15)>, <ProductCategories: ProductCategories object (16)>, <ProductCategories: ProductCategories object (17)>, <ProductCategories: ProductCategories object (18)>, <ProductCategories: ProductCategories object (19)>, <ProductCategories: ProductCategories object (20)>, <ProductCategories: ProductCategories object (21)>, <ProductCategories: ProductCategories object (22)>, <ProductCategories: ProductCategories object (23)>, <ProductCategories: ProductCategories object (24)>, <ProductCategories: ProductCategories object (25)>, <ProductCategories: ProductCategories object (26)>, <ProductCategories: ProductCategories object (27)>, <ProductCategories: ProductCategories object (28)>, <ProductCategories: ProductCategories object (29)>, <ProductCategories: ProductCategories object (30)>, '...(remaining elements truncated)...']>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProductCategories.objects.select_related('cropped_source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExtractSave():\n",
    "    def __init__(self):\n",
    "        self.left = []\n",
    "        self.top = []\n",
    "        self.right = []\n",
    "        self.bottom = []\n",
    "        self.origin_url = []\n",
    "        self.cropped_url = []\n",
    "        self.shape_source = []\n",
    "        self.cover_source = []\n",
    "        self.charm_source = []\n",
    "        self.pattern_source = []\n",
    "        self.width = []\n",
    "        self.height = []\n",
    "    \n",
    "    def get_image_size(self, resp):\n",
    "        from PIL import Image\n",
    "        byteImgIO = BytesIO()\n",
    "        byteImg = Image.open(BytesIO(resp.content))\n",
    "        byteImg.convert('RGB').save(byteImgIO, \"JPEG\")\n",
    "        byteImgIO.seek(0)\n",
    "        byteImg = byteImgIO.read()\n",
    "        dataBytesIO = BytesIO(byteImg)\n",
    "        image = Image.open(dataBytesIO)\n",
    "        image = image.convert('RGB')\n",
    "        width, height = image.size\n",
    "        return width, height\n",
    "    \n",
    "    def get_boxinfo_and_append(self, obj, url):\n",
    "        self.origin_url.append(url)\n",
    "        resp = requests.get(url)\n",
    "        w, h = self.get_image_size(resp)\n",
    "        self.width.append(w)\n",
    "        self.height.append(h)\n",
    "        self.left.append(obj.left*w)\n",
    "        self.top.append(obj.top*h)\n",
    "        self.right.append(obj.right*w)\n",
    "        self.bottom.append(obj.bottom*h)\n",
    "        \n",
    "    def get_category_and_append(self, obj, url):\n",
    "        self.cropped_url.append(url)\n",
    "        self.shape_source.append(obj.shape_source_id)\n",
    "    \n",
    "    def save_boxinfo_to_csv(self, filename):\n",
    "        dic = {}\n",
    "        dic['left'] = self.left\n",
    "        dic['top'] = self.top\n",
    "        dic['right'] = self.right\n",
    "        dic['bottom'] = self.bottom\n",
    "        dic['origin_url'] = self.origin_url\n",
    "        dic['width'] = self.width\n",
    "        dic['height'] = self.height\n",
    "    \n",
    "        test_data_pd=pd.DataFrame.from_dict(dic)\n",
    "        print(filename)\n",
    "        test_data_pd.to_csv(filename, mode='w', index=False)\n",
    "        print('...completed')\n",
    "        print('\\n')\n",
    "    \n",
    "    def save_category_to_csv(self, filename):\n",
    "        dic = {}\n",
    "        dic['cropped_url'] = self.cropped_url\n",
    "        dic['shape_source'] = self.shape_source\n",
    "        \n",
    "        test_data_pd=pd.DataFrame.from_dict(dic)\n",
    "        print(filename)\n",
    "        test_data_pd.to_csv(filename, mode='w', index=False)\n",
    "        print('...completed')\n",
    "        print('\\n')\n",
    "        \n",
    "    def save_boxing_data_to_csv(self, filename, queryset):       \n",
    "        print(queryset.count(), ' 개 data extract start')\n",
    "        i = 0\n",
    "        for c in queryset:\n",
    "            i +=1\n",
    "            if i%50==0:\n",
    "                print('making... ',i,'/ ',c)\n",
    "            if c.origin_source.image:\n",
    "                url = c.origin_source.image.url\n",
    "                self.get_boxinfo_and_append(c, url)\n",
    "            elif c.origin_source.s3_image_url:\n",
    "                url = c.origin_source.s3_image_url\n",
    "                self.get_boxinfo_and_append(c, url)\n",
    "        self.save_boxinfo_to_csv(filename)\n",
    "        \n",
    "    def save_labeling_data_to_csv(self, filename, queryset):       \n",
    "        print(queryset.count(), ' 개 data extract start')\n",
    "        i = 0\n",
    "        for c in queryset:\n",
    "            i +=1\n",
    "            if i%50==0:\n",
    "                print('making... ',i,'/ ',c)\n",
    "            if c.cropped_source.image:\n",
    "                url = c.cropped_source.image.url\n",
    "                self.get_category_and_append(c, url)\n",
    "        self.save_category_to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3DownloadManager(): # download from queryset\n",
    "        def __init__(self):\n",
    "            self.access_key = load_credential(\"AWS_ACCESS_KEY_ID\",\"\")\n",
    "            self.secret_access_key = load_credential(\"AWS_SECRET_ACCESS_KEY\",\"\")\n",
    "            self.s3 =  boto3.resource('s3',\n",
    "                                    aws_access_key_id=ACCESS_KEY,\n",
    "                                    aws_secret_access_key=SECRET_ACCESS_KEY)\n",
    "            self.temp_bucket_list = self.get_s3_file_temp_bucket()\n",
    "            self.mondedata_bucket_list = self.get_s3_file_mondedata_bucket()\n",
    "            self.cropped_bucket_list = self.get_s3_file_cropdata_bucket()\n",
    "            \n",
    "        def get_s3_file_temp_bucket(self):\n",
    "            lists = []\n",
    "            for s3_file in self.s3.Bucket('temp-originalimage').objects.all():\n",
    "                lists.append(s3_file.key)\n",
    "            return lists\n",
    "        \n",
    "        def get_s3_file_mondedata_bucket(self):\n",
    "            lists = []\n",
    "            for s3_file in self.s3.Bucket('monde-data').objects.all():\n",
    "                if s3_file.key.split('/')[0] == 'original-bag-images-dev':\n",
    "                    lists.append(s3_file.key)\n",
    "            return lists\n",
    "        \n",
    "        def get_s3_file_cropdata_bucket(self):\n",
    "            lists = []\n",
    "            for s3_file in self.s3.Bucket('monde-data').objects.all():\n",
    "                if s3_file.key.split('/')[0] == 'cropped-bag-images-dev':\n",
    "                    lists.append(s3_file.key)\n",
    "            return lists\n",
    "        \n",
    "        # s3_image_url 이 존재할 때\n",
    "        def get_origin_list_from_queryset(self, queryset, n):\n",
    "            new_file_list_t = []\n",
    "            new_file_list_m = []\n",
    "            \n",
    "            qs_temp_bucket = queryset.filter(origin_source__s3_image_url__isnull=False)\n",
    "            temp_bucket_list = []\n",
    "            qs_mondedata_bucket = queryset.exclude(origin_source__image=\"\")\n",
    "            mondedata_bucket_list = []\n",
    "            \n",
    "            for q in qs_temp_bucket:\n",
    "                q = q.origin_source\n",
    "                name = q.s3_image_url.split('/')[-1]\n",
    "                temp_bucket_list.append(name)\n",
    "                \n",
    "            for q in qs_mondedata_bucket:\n",
    "                q = q.origin_source\n",
    "                name = q.image.name\n",
    "                mondedata_bucket_list.append(name)\n",
    "            \n",
    "            pre_temp_bucket_list = self.temp_bucket_list\n",
    "            \n",
    "            #temp_bucket\n",
    "            for i in range(len(pre_temp_bucket_list)):\n",
    "                for j in range(len(temp_bucket_list)):\n",
    "                    if(pre_temp_bucket_list[i] == temp_bucket_list[j]):\n",
    "                        new_file_list_t.append(pre_temp_bucket_list[i])\n",
    "        \n",
    "            pre_mondedata_bucket_list = self.mondedata_bucket_list\n",
    "            \n",
    "            #mondedata_bucket\n",
    "            for i in range(len(pre_mondedata_bucket_list)):\n",
    "                for j in range(len(mondedata_bucket_list)):\n",
    "                    if(pre_mondedata_bucket_list[i] == mondedata_bucket_list[j]):\n",
    "                        new_file_list_m.append(pre_mondedata_bucket_list[i])\n",
    "                        \n",
    "            if n == 1: # temp bucket\n",
    "                return new_file_list_t\n",
    "            elif n == 2:\n",
    "                return new_file_list_m\n",
    "            else:\n",
    "                print('ERROR')\n",
    "                \n",
    "        def get_cropped_list_from_queryset(self, queryset):\n",
    "            new_file_list = []\n",
    "            \n",
    "            qs_cropped_bucket = queryset.exclude(cropped_source__image=\"\")\n",
    "            cropped_bucket_list_m = []\n",
    "            \n",
    "            for q in qs_cropped_bucket:\n",
    "                q = q.cropped_source\n",
    "                name = q.image.name\n",
    "                cropped_bucket_list_m.append(name)\n",
    "            \n",
    "            pre_cropped_bucket_list = self.cropped_bucket_list\n",
    "            \n",
    "            for i in range(len(pre_cropped_bucket_list)):\n",
    "                for j in range(len(cropped_bucket_list_m)):\n",
    "                    if(pre_cropped_bucket_list[i] == cropped_bucket_list_m[j]):\n",
    "                        new_file_list.append(pre_cropped_bucket_list[i])\n",
    "                        \n",
    "            return new_file_list\n",
    "    \n",
    "        def download_origin_s3_files_from_queryset(self, local_path, queryset):\n",
    "            # local_path 는 jupyter를 실행한 폴더 기준\n",
    "            # 폴더 경로는 \\\\로 끝나야 함 (for Window)\n",
    "            file_list_t = self.get_origin_list_from_queryset(queryset, 1)\n",
    "            file_list_m = self.get_origin_list_from_queryset(queryset, 2)\n",
    "            print('Start download images')\n",
    "            i = 0\n",
    "            for file in file_list_t:\n",
    "                i += 1\n",
    "                KEY = file\n",
    "                dest_pathname = os.path.join(local_path, KEY)\n",
    "                if i % 100 == 0:\n",
    "                    print(i)\n",
    "                    print(KEY)\n",
    "                try:\n",
    "                    self.s3.Bucket('temp-originalimage').download_file(KEY, dest_pathname)\n",
    "                except botocore.exceptions.ClientError as e:\n",
    "                    if e.response['Error']['Code'] == \"404\":\n",
    "                        print(\"The object does not exist.\")\n",
    "                    else:\n",
    "                        print('----')\n",
    "                        raise\n",
    "            print(i,' 개 downloaded from temp bucket')\n",
    "        \n",
    "            i = 0\n",
    "            for file in file_list_m:\n",
    "                i += 1\n",
    "                KEY = file\n",
    "                path_key = KEY.split('/')[1]\n",
    "                dest_pathname = os.path.join(local_path, path_key)\n",
    "                if i % 100 == 0:\n",
    "                    print(i)\n",
    "                    print(KEY)\n",
    "                try:\n",
    "                    self.s3.Bucket('monde-data').download_file(KEY, dest_pathname)\n",
    "                except botocore.exceptions.ClientError as e:\n",
    "                    if e.response['Error']['Code'] == \"404\":\n",
    "                        print(\"The object does not exist.\")\n",
    "                    else:\n",
    "                        print('----')\n",
    "                        raise\n",
    "            print(i,' 개 downloaded from monde-data bucket')\n",
    "            print('DONE')\n",
    "            \n",
    "        def download_cropped_s3_files_from_queryset(self, local_path, queryset):\n",
    "            # local_path 는 jupyter를 실행한 폴더 기준\n",
    "            # 폴더 경로는 \\\\로 끝나야 함 (for Window)\n",
    "            file_list = self.get_cropped_list_from_queryset(queryset)\n",
    "            \n",
    "            print('Start download images')\n",
    "            i = 0\n",
    "            for file in file_list:\n",
    "                i += 1\n",
    "                KEY = file\n",
    "                dest_pathname = os.path.join(local_path, KEY)\n",
    "                if i % 100 == 0:\n",
    "                    print(i)\n",
    "                    print(KEY)\n",
    "                try:\n",
    "                    self.s3.Bucket('monde-data').download_file(KEY, dest_pathname)\n",
    "                except botocore.exceptions.ClientError as e:\n",
    "                    if e.response['Error']['Code'] == \"404\":\n",
    "                        print(\"The object does not exist.\")\n",
    "                    else:\n",
    "                        print('----')\n",
    "                        raise\n",
    "            print(i,' 개 downloaded from monde-data bucket')\n",
    "            print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance생성 및 queryset 선언\n",
    "extractmanager1= DataExtractSave()\n",
    "imagedownloadmanager1 = S3DownloadManager()\n",
    "queryset1 = CroppedImage.objects.filter(origin_source__image_url__isnull=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queryset info download csv form\n",
    "extractmanager1.save_data_to_csv(\"crop_download_test.csv\", queryset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image download to 'data' folder => 다운받기 전 'data'라는 폴더 생성해야 합니다.\n",
    "imagedownloadmanager1.download_s3_files_from_queryset('./data/', queryset1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image review (몸체만 정확히 박싱된 데이터) extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractmanager2= DataExtractSave()\n",
    "imagedownloadmanager2 = S3DownloadManager()\n",
    "queryset2 = CroppedImage.objects.filter(origin_source__image_review=True)\n",
    "a = ShapeTag.objects.first()\n",
    "q = CroppedImage.objects.filter(categories__shape_source=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223  개 data download start\n",
      "making...  50 /  CroppedImage object (10088)\n",
      "making...  100 /  CroppedImage object (10141)\n",
      "making...  150 /  CroppedImage object (10194)\n",
      "making...  200 /  CroppedImage object (10248)\n",
      "test.csv\n",
      "downloaded\n",
      "Start download images\n",
      "100\n",
      "square_216_5Y5I61OPPTU_1.jpg\n",
      "186  개 downloaded from temp bucket\n",
      "37  개 downloaded from monde-data bucket\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "extractmanager2.save_data_to_csv(\"test.csv\", q)\n",
    "imagedownloadmanager2.download_s3_files_from_queryset('./data/', q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labeling data extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523  개 data extract start\n",
      "making...  50 /  ProductCategories object (60)\n",
      "making...  100 /  ProductCategories object (112)\n",
      "making...  150 /  ProductCategories object (162)\n",
      "making...  200 /  ProductCategories object (212)\n",
      "making...  250 /  ProductCategories object (262)\n",
      "making...  300 /  ProductCategories object (312)\n",
      "making...  350 /  ProductCategories object (362)\n",
      "making...  400 /  ProductCategories object (412)\n",
      "making...  450 /  ProductCategories object (462)\n",
      "making...  500 /  ProductCategories object (512)\n",
      "making...  550 /  ProductCategories object (562)\n",
      "making...  600 /  ProductCategories object (612)\n",
      "making...  650 /  ProductCategories object (662)\n",
      "making...  700 /  ProductCategories object (712)\n",
      "making...  750 /  ProductCategories object (762)\n",
      "making...  800 /  ProductCategories object (812)\n",
      "making...  850 /  ProductCategories object (862)\n",
      "making...  900 /  ProductCategories object (912)\n",
      "making...  950 /  ProductCategories object (962)\n",
      "making...  1000 /  ProductCategories object (1012)\n",
      "making...  1050 /  ProductCategories object (1062)\n",
      "making...  1100 /  ProductCategories object (1112)\n",
      "making...  1150 /  ProductCategories object (1162)\n",
      "making...  1200 /  ProductCategories object (1212)\n",
      "making...  1250 /  ProductCategories object (1262)\n",
      "making...  1300 /  ProductCategories object (1312)\n",
      "making...  1350 /  ProductCategories object (1362)\n",
      "making...  1400 /  ProductCategories object (1412)\n",
      "making...  1450 /  ProductCategories object (1462)\n",
      "making...  1500 /  ProductCategories object (1512)\n",
      "shape_labeling.csv\n",
      "...completed\n",
      "\n",
      "\n",
      "Start download images\n",
      "100\n",
      "cropped-bag-images-dev/2EV5CXY7CCK_1.jpg\n",
      "200\n",
      "cropped-bag-images-dev/4NP1C2HLWPJ_1.jpg\n",
      "300\n",
      "cropped-bag-images-dev/6YRPB3M3KPT_2.jpg\n",
      "400\n",
      "cropped-bag-images-dev/94WOW0YAAHF_1.jpg\n",
      "500\n",
      "cropped-bag-images-dev/BDSRJNSEYWT_1.jpg\n",
      "600\n",
      "cropped-bag-images-dev/DQH02JT33OR_1.jpg\n",
      "700\n",
      "cropped-bag-images-dev/GLW4XVFG0YZ_2.jpg\n",
      "800\n",
      "cropped-bag-images-dev/IQGF3UVPWIK_1.jpg\n",
      "900\n",
      "cropped-bag-images-dev/L4DMYEZHM9Z_1.jpg\n",
      "1000\n",
      "cropped-bag-images-dev/NC1W2SR31SS_1.jpg\n",
      "1100\n",
      "cropped-bag-images-dev/PS4NUM5Z48M_1.jpg\n",
      "1200\n",
      "cropped-bag-images-dev/S7ESRRTJTPX_1.jpg\n",
      "1300\n",
      "cropped-bag-images-dev/UDKU2GB2M9B_1.jpg\n",
      "1400\n",
      "cropped-bag-images-dev/X040RC8EP8I_1.jpg\n",
      "1500\n",
      "cropped-bag-images-dev/ZH11KCXVTQO_1.jpg\n",
      "1523  개 downloaded from monde-data bucket\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "extractmanager3 = DataExtractSave()\n",
    "imagedownloadmanager3 = S3DownloadManager()\n",
    "queryset3 = ProductCategories.objects.filter(shape_source_id__isnull=False)\n",
    "extractmanager3.save_labeling_data_to_csv(\"shape_labeling.csv\", queryset3)\n",
    "imagedownloadmanager3.download_cropped_s3_files_from_queryset('./labeling_data/', queryset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : 현재는 박싱 서버에서 쌓은 데이터 기반으로 사용 가능하지만, 추후 mondebro에서 태깅한 데이터도 사용 가능하게 수정해야 합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
