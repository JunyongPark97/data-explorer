{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import django\n",
    "import os\n",
    "import json\n",
    "os.environ['DJANGO_SETTINGS_MODULE'] = 'django_settings'\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from boto3.session import Session\n",
    "import boto3\n",
    "import botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_management.models import *\n",
    "from loader import load_credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY = load_credential(\"AWS_ACCESS_KEY_ID\",\"\")\n",
    "SECRET_ACCESS_KEY = load_credential(\"AWS_SECRET_ACCESS_KEY\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<QuerySet [<CroppedImage: CroppedImage object (178)>, <CroppedImage: CroppedImage object (179)>, <CroppedImage: CroppedImage object (180)>, <CroppedImage: CroppedImage object (181)>, <CroppedImage: CroppedImage object (182)>, <CroppedImage: CroppedImage object (183)>, <CroppedImage: CroppedImage object (184)>, <CroppedImage: CroppedImage object (185)>, <CroppedImage: CroppedImage object (186)>, <CroppedImage: CroppedImage object (187)>, <CroppedImage: CroppedImage object (188)>, <CroppedImage: CroppedImage object (189)>, <CroppedImage: CroppedImage object (190)>, <CroppedImage: CroppedImage object (191)>, <CroppedImage: CroppedImage object (192)>, <CroppedImage: CroppedImage object (193)>, <CroppedImage: CroppedImage object (194)>, <CroppedImage: CroppedImage object (195)>, <CroppedImage: CroppedImage object (196)>, <CroppedImage: CroppedImage object (197)>, '...(remaining elements truncated)...']>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CroppedImage.objects.select_related('origin_source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExtractSave():\n",
    "    def __init__(self):\n",
    "        self.left = []\n",
    "        self.top = []\n",
    "        self.right = []\n",
    "        self.bottom = []\n",
    "        self.origin_url = []\n",
    "        self.width = []\n",
    "        self.height = []\n",
    "    \n",
    "    def get_image_size(self, resp):\n",
    "        from PIL import Image\n",
    "        byteImgIO = BytesIO()\n",
    "        byteImg = Image.open(BytesIO(resp.content))\n",
    "        byteImg.convert('RGB').save(byteImgIO, \"JPEG\")\n",
    "        byteImgIO.seek(0)\n",
    "        byteImg = byteImgIO.read()\n",
    "        dataBytesIO = BytesIO(byteImg)\n",
    "        image = Image.open(dataBytesIO)\n",
    "        image = image.convert('RGB')\n",
    "        width, height = image.size\n",
    "        return width, height\n",
    "    \n",
    "    def get_data_and_append(self, obj, url):\n",
    "        self.origin_url.append(url)\n",
    "        resp = requests.get(url)\n",
    "        w, h = self.get_image_size(resp)\n",
    "        self.width.append(w)\n",
    "        self.height.append(h)\n",
    "        self.left.append(obj.left*w)\n",
    "        self.top.append(obj.top*h)\n",
    "        self.right.append(obj.right*w)\n",
    "        self.bottom.append(obj.bottom*h)\n",
    "    \n",
    "    def save_to_csv(self,  filename):\n",
    "        dic = {}\n",
    "        dic['left'] = self.left\n",
    "        dic['top'] = self.top\n",
    "        dic['right'] = self.right\n",
    "        dic['bottom'] = self.bottom\n",
    "        dic['origin_url'] = self.origin_url\n",
    "        dic['width'] = self.width\n",
    "        dic['height'] = self.height\n",
    "    \n",
    "        test_data_pd=pd.DataFrame.from_dict(dic)\n",
    "        print(filename)\n",
    "        test_data_pd.to_csv(filename, mode='w', index=False)\n",
    "        print('downloaded')\n",
    "        \n",
    "    def save_data_to_csv(self, filename, queryset):       \n",
    "        print(queryset.count())\n",
    "        i = 0\n",
    "        for c in queryset:\n",
    "            i +=1\n",
    "            if i%50==0:\n",
    "                print(i,'/ ',c)\n",
    "            if c.origin_source.image:\n",
    "                url = c.origin_source.image.url\n",
    "                self.get_data_and_append(c, url)\n",
    "            elif c.origin_source.s3_image_url:\n",
    "                url = c.origin_source.s3_image_url\n",
    "                self.get_data_and_append(c, url)\n",
    "        self.save_to_csv(filename)\n",
    "        print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3DownloadManager(): # download from queryset\n",
    "        def __init__(self):\n",
    "            self.access_key = load_credential(\"AWS_ACCESS_KEY_ID\",\"\")\n",
    "            self.secret_access_key = load_credential(\"AWS_SECRET_ACCESS_KEY\",\"\")\n",
    "            self.s3 =  boto3.resource('s3',\n",
    "                                    aws_access_key_id=ACCESS_KEY,\n",
    "                                    aws_secret_access_key=SECRET_ACCESS_KEY)\n",
    "            self.temp_bucket_list = self.get_s3_file_temp_bucket()\n",
    "            self.mondedata_bucket_list = self.get_s3_file_mondedata_bucket()\n",
    "            \n",
    "        \n",
    "        def get_s3_file_temp_bucket(self):\n",
    "            lists = []\n",
    "            for s3_file in self.s3.Bucket('temp-originalimage').objects.all():\n",
    "                lists.append(s3_file.key)\n",
    "            return lists\n",
    "        \n",
    "        def get_s3_file_mondedata_bucket(self):\n",
    "            lists = []\n",
    "            for s3_file in self.s3.Bucket('monde-data').objects.all():\n",
    "                if s3_file.key.split('/')[0] == 'original-bag-images-dev':\n",
    "                    lists.append(s3_file.key)\n",
    "            return lists\n",
    "        \n",
    "        # s3_image_url 이 존재할 때\n",
    "        def get_list_from_queryset(self, queryset, n):\n",
    "            new_file_list_t = []\n",
    "            new_file_list_m = []\n",
    "            \n",
    "            qs_temp_bucket = queryset.filter(s3_image_url__isnull=False)\n",
    "            temp_bucket_list = []\n",
    "            qs_mondedata_bucket = queryset.exclude(image=\"\")\n",
    "            mondedata_bucket_list = []\n",
    "            \n",
    "            for q in qs_temp_bucket:\n",
    "                name = q.s3_image_url.split('/')[-1]\n",
    "                temp_bucket_list.append(name)\n",
    "                \n",
    "            for q in qs_mondedata_bucket:\n",
    "                name = q.image.name\n",
    "                mondedata_bucket_list.append(name)\n",
    "            \n",
    "            pre_temp_bucket_list = self.temp_bucket_list\n",
    "            \n",
    "            #temp_bucket\n",
    "            for i in range(len(pre_temp_bucket_list)):\n",
    "                for j in range(len(temp_bucket_list)):\n",
    "                    if(pre_temp_bucket_list[i] == temp_bucket_list[j]):\n",
    "                        new_file_list_t.append(pre_temp_bucket_list[i])\n",
    "        \n",
    "            pre_mondedata_bucket_list = self.mondedata_bucket_list\n",
    "            \n",
    "            #mondedata_bucket\n",
    "            for i in range(len(pre_mondedata_bucket_list)):\n",
    "                for j in range(len(mondedata_bucket_list)):\n",
    "                    if(pre_mondedata_bucket_list[i] == mondedata_bucket_list[j]):\n",
    "                        new_file_list_m.append(pre_mondedata_bucket_list[i])\n",
    "                        \n",
    "            if n == 1: # temp bucket\n",
    "                return new_file_list_t\n",
    "            elif n == 2:\n",
    "                return new_file_list_m\n",
    "            else:\n",
    "                print('ERROR')\n",
    "    \n",
    "        def download_s3_files_from_queryset(self, local_path, queryset):\n",
    "            # local_path 는 jupyter를 실행한 폴더 기준\n",
    "            # 폴더 경로는 \\\\로 끝나야 함 (for Window)\n",
    "            file_list_t = self.get_list_from_queryset(queryset, 1)\n",
    "            file_list_m = self.get_list_from_queryset(queryset, 2)\n",
    "            i = 0\n",
    "            for file in file_list_t:\n",
    "                i += 1\n",
    "                KEY = file\n",
    "                dest_pathname = os.path.join(local_path, KEY)\n",
    "                if i % 100 == 0:\n",
    "                    print(i)\n",
    "                    print(KEY)\n",
    "                try:\n",
    "                    self.s3.Bucket('temp-originalimage').download_file(KEY, dest_pathname)\n",
    "                except botocore.exceptions.ClientError as e:\n",
    "                    if e.response['Error']['Code'] == \"404\":\n",
    "                        print(\"The object does not exist.\")\n",
    "                    else:\n",
    "                        print('----')\n",
    "                        raise\n",
    "            print('======')\n",
    "        \n",
    "            i = 0\n",
    "            for file in file_list_m:\n",
    "                i += 1\n",
    "                KEY = file\n",
    "                path_key = KEY.split('/')[1]\n",
    "                dest_pathname = os.path.join(local_path, path_key)\n",
    "                if i % 100 == 0:\n",
    "                    print(i)\n",
    "                    print(KEY)\n",
    "                try:\n",
    "                    self.s3.Bucket('monde-data').download_file(KEY, dest_pathname)\n",
    "                except botocore.exceptions.ClientError as e:\n",
    "                    if e.response['Error']['Code'] == \"404\":\n",
    "                        print(\"The object does not exist.\")\n",
    "                    else:\n",
    "                        print('----')\n",
    "                        raise\n",
    "            print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance생성 및 queryset 선언\n",
    "extractmanager1= DataExtractSave()\n",
    "imagedownloadmanager1 = S3DownloadManager()\n",
    "queryset1 = CroppedImage.objects.filter(origin_source__image_url__isnull=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queryset info download csv form\n",
    "extractmanager1.save_data_to_csv(\"crop_download_test.csv\", queryset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image download to 'data' folder => 다운받기 전 'data'라는 폴더 생성해야 합니다.\n",
    "imagedownloadmanager1.download_s3_files_from_queryset('./data/', queryset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### image review (몸체만 정확히 박싱된 데이터) extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractmanager2= DataExtractSave()\n",
    "imagedownloadmanager2 = S3DownloadManager()\n",
    "queryset2 = CroppedImage.objects.filter(origin_source__image_review=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractmanager2.save_data_to_csv(\"20191106_tight_boxed_data.csv\", queryset2)\n",
    "imagedownloadmanager2.download_s3_files_from_queryset('./data/', queryset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : 현재는 박싱 서버에서 쌓은 데이터 기반으로 사용 가능하지만, 추후 mondebro에서 태깅한 데이터도 사용 가능하게 수정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
